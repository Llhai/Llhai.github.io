<!DOCTYPE html>
<html>
<head hexo-theme="https://volantis.js.org/#2.6.6">
  <meta charset="utf-8" />
  <!-- SEO相关 -->
    
  <!-- 渲染优化 -->
  <meta name="renderer" content="webkit" />
  <meta name="force-rendering" content="webkit" />
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, maximum-scale=1"
  />

  <!-- 页面元数据 -->
  
  <title>机器学习-7-Tips-For-Training-DNN - LlHai</title>
   
  <meta name="description" content="本节介绍训练神经网络模型时的一些知识点，针对模型在训练集和测试集的表现，针对性地给出解决方法" />
  

  <!-- feed -->
  

  <!-- import meta -->
  

  <!-- link -->
  <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13/css/all.min.css"
  />
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
    

  <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq"
    crossorigin="anonymous"
  />

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"
  ></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous"
    onload="renderMathInElement(document.body);"
  ></script>

  <!-- import link -->
     
<link rel="stylesheet" href="/css/style.css">
 

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById("loading-bar").style.width = num + "%";
    }
  </script>

   
</head>

<body>
  
  <div id="loading-bar-wrapper">
  <div id="loading-bar"></div>
</div>
<header class="l_header shadow blur">
  <div class='container'>
  <div class='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h'>
        <li><a class="s-comment fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
          
          
            你说的对
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h'>
          
          
          
            
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

<script>setLoadingBarProgress(40);</script>



  <div class="l_body nocover">
    <div class='body-wrapper'>
      

<div class='l_main'>
  

  
    <article id="post" class="post white-box reveal shadow article-type-post" itemscope itemprop="blogPost">
      


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h1 class="title">
    <a href="/2020/08/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-7-Tips-For-Training-DNN/">
      机器学习-7-Tips-For-Training-DNN
    </a>
  </h1>


        
        <div class='new-meta-box'>
          
            
          
            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/ML2020%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>ML2020课程笔记</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：Aug 9, 2020</p>
  </a>
</div>

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


      <section class="article typo">
        <div class="article-entry" itemprop="articleBody">
          
          <h4 id="深度学习的三个步骤"><a class="markdownIt-Anchor" href="#深度学习的三个步骤"></a> 深度学习的三个步骤</h4>
<p>通过之前的学习，我们了解到深度学习分为以下三个步骤:</p>
<ul>
<li>设计模型网络结构(network structure)</li>
<li>定义损失函数(goodness of function)</li>
<li>选择合适的方法训练模型(pick the best function)</li>
</ul>
<center><img src="https://cdn.jsdelivr.net/gh/Llhai/img/source/ML2020/DeepLearning/recipe-dl.png" width="60%;" /></center>
<h4 id="tips-for-training-learning"><a class="markdownIt-Anchor" href="#tips-for-training-learning"></a> Tips for Training Learning</h4>
<p>在模型训练时通常存在以下两个问题：</p>
<ul>
<li>在 training set 上的 performance 不够好</li>
<li>在 testing set 上的 performance 不够好</li>
</ul>
<p>对于这两个问题，我们需要针对性地进行解决。举例来说，最近提出的 dropout 方法很好很强大，所以今天只要看到 performance 不好，我就去用 dropout；但是，其实只有在 testing 的结果不好的时候，才可以去 apply dropout，如果你今天的问题只是 training 的结果不好，那你去 apply dropout，只会越 train 越差而已。所以，你<strong>必须要先想清楚现在的问题到底是什么，然后再根据这个问题去找针对性的方法</strong>。下面我们分别从 Training data 和 Testing data 两个问题出发，来讲述一些针对性优化的方法。</p>
<h5 id="good-results-on-training-data"><a class="markdownIt-Anchor" href="#good-results-on-training-data"></a> Good Results on Training Data？</h5>
<p>我们训练模型的第一个目标就是，<strong>提高 model 在 training set 上的正确率</strong>，课程给出了两个在 Training data 上得到更好的 performance 的方法，分别是：New activation function 和 Adaptive Learning Rate</p>
<h5 id="new-activation-function"><a class="markdownIt-Anchor" href="#new-activation-function"></a> New activation function</h5>
<p>如果你今天的 training 结果不好，很有可能是因为你的 network 架构设计得不好。举例来说，可能你用的 activation function 是对 training 比较不利的，那你就尝试着换一些新的 activation function，也许可以带来比较好的结果。</p>
<p>比如传统的 activation function 是 sigmoid function，就会存在梯度消失(Vanishing Gradient Problem)的问题。具体表现为当时网络结构 deeper 到一定程度后，模型表现崩溃式下降，具体原因如下：</p>
<p>当你把 network 叠得很深的时候，在靠近 input 的地方，这些参数的 gradient(即对最后 loss function 的微分)是比较小的；而在比较靠近 output 的地方，它对 loss 的微分值会是比较大的</p>
<p>因此当你设定同样 learning rate 的时候，靠近 input 的地方，它参数的 update 是很慢的；而靠近 output 的地方，它参数的 update 是比较快的</p>
<p>所以在靠近 input 的地方，参数几乎还是 random 的时候，output 就已经根据这些 random 的结果找到了一个 local minima，然后就 converge(收敛)了</p>
<p>这个时候你会发现，参数的 loss 下降的速度变得很慢，你就会觉得 gradient 已经接近于 0 了，于是把程序停掉了，由于这个 converge，是几乎 base on random 的参数，所以 model 的参数并没有被训练充分，那在 training data 上得到的结果肯定是很差的。</p>
<p>为了解决这个问题，提出了许多新的 activation function</p>
<h6 id="relu"><a class="markdownIt-Anchor" href="#relu"></a> ReLU</h6>
<p>现在比较常用的 activation function 叫做 Rectified Linear Unit(整流线性单元函数，又称修正线性单元)，它的缩写是 ReLU，该函数形状如下图所示，z 为 input，a 为 output，如果 input&gt;0 则 output = input，如果 input&lt;0 则 output = 0</p>
<center><img src="https://cdn.jsdelivr.net/gh/Llhai/img/source/ML2020/DeepLearning/ReLU1.png" width="60%;" /></center>
<p>relu 有以下几点好处：</p>
<ul>
<li>relu 的线性结构，运算速度比 sigmoid 快很多</li>
<li>relu 可以解决梯度消失的问题，当 output=input 的时候，这个 activation function 就是 linear 的；而 output=0 的 neuron 对整个 network 是没有任何作用的，因此可以把它们从 network 中拿掉，拿掉所有 output 为 0 的 neuron 后，整个 network 就变成了一个瘦长的 linear network，linear 的好处是，output=input，不会像 sigmoid function 一样使 input 产生的影响逐层递减。</li>
</ul>
<p>ReLU 还存在一定的问题，比如当 input&lt;0 的时候，output=0，此时微分值 gradient 也为 0，你就没有办法去 update 参数了，所以我们应该让 input&lt;0 的时候，微分后还能有一点点的值，比如令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi><mo>=</mo><mn>0.01</mn><mi>z</mi></mrow><annotation encoding="application/x-tex">a=0.01z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">1</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span></span></span></span>，这个东西就叫做<strong>Leaky ReLU</strong></p>
<center><img src="https://cdn.jsdelivr.net/gh/Llhai/img/source/ML2020/DeepLearning/relu-variant.png" width="60%;" /></center>
<h6 id="maxout"><a class="markdownIt-Anchor" href="#maxout"></a> Maxout</h6>
<p>Maxout 的想法是，让 network 自动去学习它的 activation function，那 Maxout network 就可以自动学出 ReLU，也可以学出其他的 activation function，这一切都是由 training data 来决定的。</p>
<p>Maxout 可以实现任何 piecewise linear convex activation function(分段线性凸激活函数)，其中这个 activation function 被分为多少段，取决于你把多少个 element z 放到一个 group 里，下图分别是 2 个 element 一组和 3 个 element 一组的 activation function 的不同形状</p>
<center><img src="https://cdn.jsdelivr.net/gh/Llhai/img/source/ML2020/DeepLearning/maxout4.png" width="60%;" /></center>
<h5 id="adaptive-learning-rate"><a class="markdownIt-Anchor" href="#adaptive-learning-rate"></a> Adaptive learning rate</h5>
<p>这个部分主要讲述的是关于 Recipe of Deep Learning 中 Adaptive learning rate 的一些理论</p>
<ul>
<li>Adagrad
<ul>
<li>Adagrad 的精神是，假设我们考虑两个参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_1,w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，如果在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>这个方向上，平常的 gradient 都比较小，那它是比较平坦的，于是就给它比较大的 learning rate；反过来说，在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>这个方向上，平常 gradient 都比较大，那它是比较陡峭的，于是给它比较小的 learning rate</li>
</ul>
</li>
<li>RMSProp
<ul>
<li>更 dynamic 的调整 learning rate 的方法，随时根据 gradient 的大小来快速地调整 learning rate</li>
</ul>
</li>
<li>Momentum
<ul>
<li>Momentum 可以解决卡在 local minimum、saddle point 或是 plateau 地方的问题</li>
<li>当我们在 gradient descent 里加上 Momentum 的时候，每一次 update 的方向，不再只考虑 gradient 的方向，还要考虑上一次 update 的方向</li>
</ul>
</li>
<li>Adam<br />
<strong>RMSProp 加上 Momentum，就可以得到 Adam</strong></li>
</ul>
<h5 id="good-results-on-training-data-2"><a class="markdownIt-Anchor" href="#good-results-on-training-data-2"></a> Good Results on Training Data？</h5>
<p>接下来你要做的事是，<strong>提高 model 在 testing set 上的正确率</strong>，假设现在你已经在 training set 上得到好的 performance 了，那接下来就把 model apply 到 testing set 上，我们最后真正关心的，是 testing set 上的 performance，假如得到的结果不好，这个情况下发生的才是 Overfitting，也就是在 training set 上得到好的结果，却在 testing set 上得到不好的结果。</p>
<h5 id="early-stopping"><a class="markdownIt-Anchor" href="#early-stopping"></a> Early Stopping</h5>
<p>假设你今天的 learning rate 调的比较好，那随着训练的进行，total loss 通常会越来越小，但是 Training set 和 Testing set 的情况并不是完全一样的，很有可能当你在 Training set 上的 loss 逐渐减小的时候，在 Testing set 上的 loss 反而上升了</p>
<p>所以，理想上假如你知道 testing data 上的 loss 变化情况，你会在 testing set 的 loss 最小的时候停下来，而不是在 training set 的 loss 最小的时候停下来；但 testing set 实际上是未知的东西，所以我们需要用 validation set 来替代它去做这件事情</p>
<h5 id="regularization"><a class="markdownIt-Anchor" href="#regularization"></a> Regularization</h5>
<p>regularization 就是在原来的 loss function 上额外增加几个 term，比如我们要 minimize 的 loss function 原先应该是 square error 或 cross entropy，那在做 Regularization 的时候，就在后面加一个 Regularization 的 term</p>
<ul>
<li>L2 regularization</li>
<li>L1 regularization</li>
</ul>
<p>我们来对比一下 L1 和 L2 的 update 过程：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mn>1</mn><mo>:</mo><msubsup><mi>w</mi><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><msubsup><mi>w</mi><mi>i</mi><mi>t</mi></msubsup><mo>−</mo><mi>η</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mi>i</mi></msub></mrow></mfrac><mo>−</mo><mi>η</mi><mi>λ</mi><mtext> </mtext><mi>s</mi><mi>g</mi><mi>n</mi><mo stretchy="false">(</mo><msubsup><mi>w</mi><mi>i</mi><mi>t</mi></msubsup><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>L</mi><mn>2</mn><mo>:</mo><msubsup><mi>w</mi><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>η</mi><mi>λ</mi><mo stretchy="false">)</mo><msubsup><mi>w</mi><mi>i</mi><mi>t</mi></msubsup><mo>−</mo><mi>η</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mi>i</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">L1: w_i^{t+1}=w_i^t-\eta \frac{\partial L}{\partial w_i}-\eta \lambda \ sgn(w_i^t)\\

L2: w_i^{t+1}=(1-\eta \lambda)w_i^t-\eta \frac{\partial L}{\partial w_i}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.131103em;vertical-align:-0.266995em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.433005em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.266995em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0905559999999999em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8435559999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.20744em;vertical-align:-0.8360000000000001em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.093556em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mord mathdefault">λ</span><span class="mspace"> </span><span class="mord mathdefault">s</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">n</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8435559999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.131103em;vertical-align:-0.266995em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.433005em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.266995em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.093556em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8435559999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.20744em;vertical-align:-0.8360000000000001em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>L1 和 L2，虽然它们同样是让参数的绝对值变小，但它们做的事情其实略有不同：</p>
<ul>
<li>L1 使参数绝对值变小的方式是每次 update<strong>减掉一个固定的值</strong></li>
<li>L2 使参数绝对值变小的方式是每次 update<strong>乘上一个小于 1 的固定值</strong></li>
</ul>
<p>因此，当参数 w 的绝对值比较大的时候，L2 会让 w 下降得更快，而 L1 每次 update 只让 w 减去一个固定的值，train 完以后可能还会有很多比较大的参数；当参数 w 的绝对值比较小的时候，L2 的下降速度就会变得很慢，train 出来的参数平均都是比较小的，而 L1 每次下降一个固定的 value，train 出来的参数是比较 sparse 的，这些参数有很多是接近 0 的值，也会有很大的值</p>
<p>在之前所讲的 CNN 的 task 里，用 L1 做出来的效果是比较合适的，是比较 sparse 的</p>
<h5 id="dropout"><a class="markdownIt-Anchor" href="#dropout"></a> Dropout</h5>
<p>这里先讲 dropout 是怎么做的，然后再来解释为什么这样做</p>
<h6 id="how-to-do-dropout"><a class="markdownIt-Anchor" href="#how-to-do-dropout"></a> How to do Dropout</h6>
<p>在 training 的时候，每次 update 参数之前，我们对每一个 neuron(也包括 input layer 的“neuron”)做 sampling(抽样) ，每个 neuron 都有 p%的几率会被丢掉，如果某个 neuron 被丢掉的话，跟它相连的 weight 也都要被丢掉</p>
<p>实际上就是每次 update 参数之前都通过抽样只保留 network 中的一部分 neuron 来做训练</p>
<p>==<strong>Dropout 真正要做的事情，就是要让你在 training set 上的结果变差，但是在 testing set 上的结果是变好的</strong>==</p>
<p>在使用 dropout 方法做 testing 的时候要注意两件事情：</p>
<ul>
<li>testing 的时候不做 dropout，所有的 neuron 都要被用到</li>
<li>假设在 training 的时候，dropout rate 是 p%，从 training data 中被 learn 出来的所有 weight 都要乘上(1-p%)才能被当做 testing 的 weight 使用</li>
</ul>
<h6 id="为什么-dropout-会有用"><a class="markdownIt-Anchor" href="#为什么-dropout-会有用"></a> 为什么 dropout 会有用？</h6>
<p>假设现在的 dropout rate 是 50%，那在 training 的时候，你总是期望每次 update 之前会丢掉一半的 neuron，就像下图左侧所示，在这种情况下你 learn 好了一组 weight 参数，然后拿去 testing</p>
<p>但是在 testing 的时候是没有 dropout 的，所以如果 testing 使用的是和 training 同一组 weight，那左侧得到的 output z 和右侧得到的 output z‘，它们的值其实是会相差两倍的，即<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>z</mi><mo mathvariant="normal">′</mo></msup><mo>≈</mo><mn>2</mn><mi>z</mi></mrow><annotation encoding="application/x-tex">z&#x27;≈2z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span></span></span></span>，这样会造成 testing 的结果与 training 的结果并不 match，最终的 performance 反而会变差</p>
<center><img src="https://cdn.jsdelivr.net/gh/Llhai/img/source/ML2020/DeepLearning/dropout6.png" width="60%;" /></center>
那这个时候，你就需要把右侧testing中所有的weight乘上0.5，然后做normalization，这样z就会等于z'，使得testing的结果与training的结果是比较match的
<p>==<strong>如果 network 很接近 linear 的话，dropout 所得到的 performance 会比较好，而 ReLU 和 Maxout 的 network 相对来说是比较接近于 linear 的，所以我们通常会把含有 ReLU 或 Maxout 的 network 与 Dropout 配合起来使用</strong>==</p>

          
            <div class='article_footer'>
              
                
  
    
    



  

  
    
    



  

  
    
    

<section class="widget copyright  desktop mobile">
  <div class='content'>
    
      <blockquote>
        
          
            <p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p>

          
        
          
            <p>本文永久链接是：<a href=http://yoursite.com/2020/08/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-7-Tips-For-Training-DNN/>http://yoursite.com/2020/08/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-7-Tips-For-Training-DNN/</a></p>
          
        
      </blockquote>
    
  </div>
</section>

  

  
    
    

<section class="widget qrcode  desktop mobile">
  

  <div class='content article-entry'>
    
      
        <div class='fancybox'><img src='https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/qrcode/wiki_volantis.png'
        
          height='64px'
        ></div>
      
    
      
        <div class='fancybox'><img src='https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/qrcode/wiki_volantis.png'
        
          height='64px'
        ></div>
      
    
  </div>
</section>

  


              
            </div>
          
        </div>
        
          


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2021-03-14T16:47:05+08:00">
  <a class='notlink'>
    <i class="fas fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：Mar 14, 2021</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E2%80%9C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%9D/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>“机器学习”</p></a></div>


        
      
        
          

        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2020/08/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-7-Tips-For-Training-DNN/&title=机器学习-7-Tips-For-Training-DNN - LlHai&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://yoursite.com/2020/08/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-7-Tips-For-Training-DNN/&title=机器学习-7-Tips-For-Training-DNN - LlHai&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2020/08/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-7-Tips-For-Training-DNN/&title=机器学习-7-Tips-For-Training-DNN - LlHai&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


        
        
          <div class="prev-next">
            
              <a class='prev' href='/2021/07/17/Spring/%E6%B3%A8%E8%A7%A3%E5%AD%97%E5%85%B8/'>
                <p class='title'><i class="fas fa-chevron-left" aria-hidden="true"></i>注解字典</p>
                <p class='content'> 注解
记录本书涉及到的所有注解
 系统注解

@Override
@Deprecated
@SuppressWarnings

 Lombok注解

@Data : 自动生成Gettter/S...</p>
              </a>
            
            
              <a class='next' href='/2020/08/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-6-BackPropagation/'>
                <p class='title'>机器学习-6-BackPropagation<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
                <p class='content'>(Backpropagation)反向传播，是在训练神经网络时使用梯度下降法的计算方法。
在神经网络中，通常有百万级别的参数，所以高效地计算出网络中参数的梯度，成为了一个难题，这就是反向传播需要...</p>
              </a>
            
          </div>
        
      </section>
    </article>
  

  
    <!-- 显示推荐文章和评论 -->



  <article class="post white-box reveal comments shadow">
    <section class="article typo">
      <p ct><i class='fas fa-comments'></i> 评论</p>
      
      
      
      
      
      
        <section id="comments">
          <div id="valine_container" class="valine_thread">
            <i class="fas fa-cog fa-spin fa-fw fa-2x"></i>
          </div>
        </section>
      
      
    </section>
  </article>


  




<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->

  <script>
  // https://github.com/theme-next/hexo-theme-next/blob/master/layout/_third-party/math/mathjax.swig
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.0/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    // 文章章节标题不能为 “MathJax” ，否则会报错。
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>




  <script>
    window.subData = {
      title: '机器学习-7-Tips-For-Training-DNN',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
  

  
    
    


  <section class="widget toc-wrapper shadow desktop mobile">
    
  <header>
    
      <i class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
      <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%89%E4%B8%AA%E6%AD%A5%E9%AA%A4"><span class="toc-text"> 深度学习的三个步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tips-for-training-learning"><span class="toc-text"> Tips for Training Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#good-results-on-training-data"><span class="toc-text"> Good Results on Training Data？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#new-activation-function"><span class="toc-text"> New activation function</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#adaptive-learning-rate"><span class="toc-text"> Adaptive learning rate</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#good-results-on-training-data-2"><span class="toc-text"> Good Results on Training Data？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#early-stopping"><span class="toc-text"> Early Stopping</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#regularization"><span class="toc-text"> Regularization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#dropout"><span class="toc-text"> Dropout</span></a></li></ol></li></ol>
    </div>
  </section>


  


</aside>


  
  <footer class="clearfix">
    <br><br>
    
      
        <div class="aplayer-container">
          


        </div>
      
    
      
        <br>
        <div class="social-wrapper">
          
            
              <a href="/atom.xml"
                class="social fas fa-rss flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
              <a href="mailto:me@xaoxuu.com"
                class="social fas fa-envelope flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
              <a href="https://github.com/xaoxuu"
                class="social fab fa-github flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
              <a href="https://music.163.com/#/user/home?id=63035382"
                class="social fas fa-headphones-alt flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
        </div>
      
    
      
        <div><p>Blog content follows the <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div>
      
    
      
        Use
        <a href="https://volantis.js.org/" target="_blank" class="codename">Volantis</a>
        as theme, total visits
          <span id="busuanzi_value_site_pv"><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span>
          times
        
      
    
      
        <div class='copyright'>
        <p><a target="_blank" rel="noopener" href="https://xaoxuu.com">Copyright © 2017-2020 Mr. X</a></p>

        </div>
      
    
  </footer>

<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4/dist/jquery.min.js"></script>


  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/instant_page.js" type="module" defer integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.6/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      ScrollReveal().reveal('.l_main .reveal', {
        distance: '8px',
        duration: '800',
        interval: '100',
        scale: '1'
      });
    });
  </script>


  
<script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>

  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script defer src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>



  
  
  
    
<script src="https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js"></script>

    <script type="text/javascript">
      $(function(){
        var imgs=["https://cdn.jsdelivr.net/gh/Llhai/img/source/wallhaven-6k3oox.jpg"];
        if ('true' == 'true') {
          function shuffle(arr){
            /*From countercurrent-time*/
            var n = arr.length;
            while(n--) {
              var index = Math.floor(Math.random() * n);
              var temp = arr[index];
              arr[index] = arr[n];
              arr[n] = temp;
            }
          }
          shuffle(imgs);
        }
        if ('.cover') {
          $('.cover').backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        } else {
          $.backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        }
      });
    </script>
  











  
    
<script src="https://cdn.jsdelivr.net/npm/valine@1.4/dist/Valine.min.js"></script>

  
  <script>
  var GUEST_INFO = ['nick','mail','link'];
  var meta = 'nick,mail,link'.split(',').filter(function(item){
    return GUEST_INFO.indexOf(item) > -1
  });
  var REQUIRED_FIELDS = ['nick','mail','link'];
  var requiredFields = 'nick,mail'.split(',').filter(function(item){
    return REQUIRED_FIELDS.indexOf(item) > -1
  });
  var valine = new Valine();
  function emoji(path, idx, ext) {
      return path + "/" + path + "-" + idx + "." + ext;
  }
  var emojiMaps = {};
  for (var i = 1; i <= 54; i++) {
    emojiMaps['tieba-' + i] = emoji('tieba', i, 'png');
  }
  for (var i = 1; i <= 101; i++) {
    emojiMaps['qq-' + i] = emoji('qq', i, 'gif');
  }
  for (var i = 1; i <= 116; i++) {
    emojiMaps['aru-' + i] = emoji('aru', i, 'gif');
  }
  for (var i = 1; i <= 125; i++) {
    emojiMaps['twemoji-' + i] = emoji('twemoji', i, 'png');
  }
  for (var i = 1; i <= 4; i++) {
    emojiMaps['weibo-' + i] = emoji('weibo', i, 'png');
  }
  valine.init({
    el: '#valine_container',
    meta: meta,
    
    appId: "8oYFiSOBgumF6fqO7mxHYSbt-gzGzoHsz",
    appKey: "4YfG5ENRdUo42aYxkI1Ds2Aj",
    placeholder: "快来评论吧~",
    pageSize:'10',
    avatar:'robohash',
    lang:'zh-cn',
    visitor: 'true',
    highlight: 'true',
    mathJax: 'false',
    enableQQ: 'true',
    requiredFields: requiredFields,
    emojiCDN: 'https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/emoji/valine/',
    emojiMaps: emojiMaps
  })
  </script>





  
<script src="/js/app.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2.6.5/js/search.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/comment_typing.js"></script>






<!-- 复制 -->

  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="fas fa-copy"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-check-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-check-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-times-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-times-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>




<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  function pjax_fancybox() {
    $(".article-entry").find("img").not('.inline').not('a img').each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 标准 markdown 描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".article-entry").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  $(function () {
    pjax_fancybox();
  });
</script>




  <script>setLoadingBarProgress(100);</script>
</body>
</html>
